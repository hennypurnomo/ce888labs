{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "np.set_printoptions(precision = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"jester-data-1.csv\", header=None)\n",
    "del data[data.columns[0]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_vali = np.zeros(user_ratings.shape) + 99.0\n",
    "user_ratings_copy = user_ratings.copy() \n",
    "count = 0\n",
    "loc_log = []\n",
    "for x in range(0,user_ratings.shape[0]):\n",
    "    for y in range(0,user_ratings.shape[1]):\n",
    "        if (user_ratings_copy[x,y]!=99.0):\n",
    "            if (np.random.random() > 0.9):\n",
    "                count += 1\n",
    "                temp = user_ratings_copy[x,y]\n",
    "                user_ratings_copy[x,y] = user_ratings_vali[x,y]\n",
    "                user_ratings_vali[x,y] = temp\n",
    "                loc_log.append((x,y))\n",
    "                #print(temp)\n",
    "print(user_ratings_vali,'\\n', count,'\\n', count/(user_ratings.shape[0]*user_ratings.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100\n",
    "latent_user_preferences = np.random.random((user_ratings.shape[0], n_features))\n",
    "latent_item_features = np.random.random((user_ratings.shape[1],n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('user_ratings.shape:           ',user_ratings.shape)\n",
    "print('latent_user_preferences.shape:',latent_user_preferences.shape)\n",
    "print('latent_item_features.shape:   ',latent_item_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_ratings, user_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse_loglist = []\n",
    "test_mse_loglist = []\n",
    "best_latent_user_preferences = latent_user_preferences.copy()\n",
    "best_latent_item_features = latent_item_features.copy()\n",
    "best_test_mse = 99999.0\n",
    "best_loc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id,item_id):\n",
    "    \"\"\" Predict a rating given a user_id and an item_id.\n",
    "    \"\"\"\n",
    "    user_preference = latent_user_preferences[user_id]\n",
    "    item_preference = latent_item_features[item_id]\n",
    "    return user_preference.dot(item_preference)  #linear\n",
    "\n",
    "def train(user_id, item_id, rating,alpha = 0.0001):\n",
    "    \n",
    "    #print (item_id)\n",
    "    prediction_rating = predict_rating(user_id, item_id)\n",
    "    err =  ( prediction_rating- rating );\n",
    "    #print (err)\n",
    "    user_pref_values = latent_user_preferences[user_id][:]\n",
    "    latent_user_preferences[user_id] -= alpha * err * latent_item_features[item_id]\n",
    "    latent_item_features[item_id] -= alpha * err * user_pref_values\n",
    "    return err\n",
    "    \n",
    "\n",
    "\n",
    "def sgd(iterations = 300000):\n",
    "    \"\"\" Iterate over all users and all items and train for \n",
    "        a certain number of iterations\n",
    "    \"\"\"\n",
    "    global best_latent_user_preferences\n",
    "    global best_latent_item_features\n",
    "    global best_test_mse\n",
    "    global best_loc\n",
    "    err_mse_log = 99999.0\n",
    "    for iteration in range(0,iterations):\n",
    "        error = []\n",
    "        vali_err = []\n",
    "        for user_id in range(0,latent_user_preferences.shape[0]):\n",
    "            for item_id in range(0,latent_item_features.shape[0]):\n",
    "                rating = user_ratings_copy[user_id][item_id]\n",
    "                if(rating != 99):\n",
    "                    err = train(user_id,item_id,rating)\n",
    "                    error.append(err)\n",
    "                    #print(rating)\n",
    "        mse = (np.array(error) ** 2).mean()\n",
    "        train_mse_loglist.append(mse)\n",
    "        err_mse = mse - err_mse_log\n",
    "        #if (err_mse>0):\n",
    "        #    print(mse, err_mse, err_mse_log)\n",
    "        #    break\n",
    "        err_mse_log = mse\n",
    "        for loc in loc_log:\n",
    "            vali_err.append(user_ratings_vali[loc[0]][loc[1]]-latent_user_preferences[loc[0]].dot(latent_item_features[loc[1]]))\n",
    "        test_mse = (np.array(vali_err) ** 2).mean()\n",
    "        test_mse_loglist.append(test_mse)\n",
    "        if (test_mse < best_test_mse):\n",
    "            best_test_mse = test_mse\n",
    "            best_latent_user_preferences = latent_user_preferences.copy()\n",
    "            best_latent_item_features = latent_item_features.copy()\n",
    "            best_loc = iteration\n",
    "        if (iteration > best_loc+100):\n",
    "            break\n",
    "        #print(iteration)\n",
    "        #if(iteration%100 == 0 ):\n",
    "        print (iteration, ':=', mse, err_mse, test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_mse_loglist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata1 = DataFrame(np.vstack((np.arange(np.array(train_mse_loglist).shape[0]), train_mse_loglist)).T, columns=['iterations', 'train_MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.lmplot(plotdata1.columns[0], plotdata1.columns[1], data=plotdata1, fit_reg=False)\n",
    "sns_plot.savefig(\"Fulltext_predictions_trainMSE_%df_%d.png\"%(n_features, best_loc), bbox_inches='tight')\n",
    "sns_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata1 = DataFrame(np.vstack((np.arange(np.array(test_mse_loglist).shape[0]), test_mse_loglist)).T, columns=['iterations', 'test_MSE'])\n",
    "sns_plot = sns.lmplot(plotdata1.columns[0], plotdata1.columns[1], data=plotdata1, fit_reg=False)\n",
    "sns_plot.savefig(\"Fulltext_predictions_testMSE_%df_%d.png\"%(n_features, best_loc), bbox_inches='tight')\n",
    "sns_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(test_mse_loglist), test_mse_loglist.index(min(test_mse_loglist)), train_mse_loglist[test_mse_loglist.index(min(test_mse_loglist))+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(train_mse_loglist), train_mse_loglist.index(min(train_mse_loglist)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_latent_user_preferences.dot(best_latent_item_features.T)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "for t in range(0, len(loc_log)):\n",
    "    #print(predictions[loc_log[t][0],loc_log[t][1]], best_latent_user_preferences[loc_log[t][0]].dot(best_latent_item_features[loc_log[t][1]]), user_ratings_vali[loc_log[t][0]][loc_log[t][1]])\n",
    "    err.append(best_latent_user_preferences[loc_log[t][0]].dot(best_latent_item_features[loc_log[t][1]])-user_ratings_vali[loc_log[t][0]][loc_log[t][1]])\n",
    "mse2 = (np.array(err) ** 2).mean()\n",
    "print(mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_err = []\n",
    "for loc in loc_log:\n",
    "    vali_err.append(user_ratings_vali[loc[0]][loc[1]]-best_latent_user_preferences[loc[0]].dot(best_latent_item_features[loc[1]]))\n",
    "test_mse = (np.array(vali_err) ** 2).mean()\n",
    "print (test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [zip(user_ratings_copy[i], predictions[i]) for i in range(0,predictions.shape[0])]\n",
    "comparison_data = pd.DataFrame(values)\n",
    "comparison_data.columns = data.columns\n",
    "comparison_data.applymap(lambda x: \"(%2.3f|%2.3f)\"%(x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [zip(user_ratings_vali[i], predictions[i]) for i in range(0,predictions.shape[0])]\n",
    "comparison_data = pd.DataFrame(values)\n",
    "comparison_data.columns = data.columns\n",
    "comparison_data.applymap(lambda x: [\"(%2.3f|%2.3f)\"%(x[0],x[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Fulltext_predictions_%df_%d.csv\"%(n_features, best_loc), predictions, delimiter=\",\")\n",
    "np.savetxt(\"Fulltext_latent_user_preferences_%df_%d.csv\"%(n_features, best_loc), best_latent_user_preferences, delimiter=\",\")\n",
    "np.savetxt(\"Fulltextlatent_item_features_%df_%d.csv\"%(n_features, best_loc), best_latent_item_features, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
